# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MrVJdXnQXIwsD-DU9txcZylSQX7yGaiX
"""

pip install Pillow

# Import the allowed library for image reading
from PIL import Image
import numpy as np # Used for efficient array creation

def read_and_convert_to_grayscale(file_path):
    # 1. READ COLOR IMAGE (Allowed Library Function)
    try:
        color_image = Image.open(file_path)
    except FileNotFoundError:
        print(f"Error: File not found at {file_path}")
        return None, None

    # Get image dimensions
    width, height = color_image.size

    # Convert image to an array for easy R, G, B access
    # This creates a 3D numpy array (Height x Width x 3)
    rgb_data = np.array(color_image, dtype=np.uint8)

    print(f"Image loaded: {width}x{height} pixels.")
    print("Starting manual grayscale conversion...")

    # 2. INITIALIZE GRAYSCALE IMAGE
    # Create a new 2D array (Height x Width) to store grayscale values (0-255)
    I_gray = np.zeros((height, width), dtype=np.uint8)

    return rgb_data, I_gray, width, height

def manual_grayscale_conversion(rgb_data, I_gray, width, height):
    # Coefficients for the ITU-R BT.601 standard
    R_COEFF = 0.299
    G_COEFF = 0.587
    B_COEFF = 0.114

    # 3. MANUAL GRAYSCALE CONVERSION (Required Implementation)
    # Loop over every pixel (y for height/rows, x for width/columns)
    for y in range(height):
        for x in range(width):
            # Manually extract R, G, B values from the 3D array
            # Assuming the image is in RGB order (Channel 0=R, 1=G, 2=B)
            R = rgb_data[y, x, 0]
            G = rgb_data[y, x, 1]
            B = rgb_data[y, x, 2]

            # Apply the required formula: I = 0.299R + 0.587G + 0.114B
            # We use float math and then round the result.
            I_float = (R_COEFF * R) + (G_COEFF * G) + (B_COEFF * B)

            # Round the result to the nearest integer and cast it back to an 8-bit unsigned integer (0-255).
            # This ensures the intensity remains an integer gray level.
            I_gray[y, x] = np.round(I_float).astype(np.uint8)

    print("Grayscale conversion complete.")
    return I_gray

# --- Main Execution ---

file_name = "data13.bmp"

# Step 1: Read and Initialize
rgb_data, I_gray, width, height = read_and_convert_to_grayscale(file_name)

if rgb_data is not None:
    # Step 2: Perform Manual Conversion
    grayscale_image_data = manual_grayscale_conversion(rgb_data, I_gray, width, height)

    # Verification (Allowed Library Functions for Writing/Displaying)
    if grayscale_image_data is not None:
        # Create a PIL Image object from the resulting numpy array
        grayscale_image = Image.fromarray(grayscale_image_data, mode='L')

        # Save the result (optional, but good for verification)
        output_file_name = "data13_grayscale.bmp"
        grayscale_image.save(output_file_name)
        print(f"Grayscale image saved to {output_file_name}")

        # Display the result (optional)
        # grayscale_image.show()
else:
    print("Image loading failed. Please check the file name and path.")

"""Manual Histogram and Global Mean CalculationThe constraints require you to manually compute the histogram and global mean without using built-in NumPy or other library functions like np.histogram() or np.mean().1. Manual Histogram CalculationThe histogram $H(j)$ counts the number of pixels for each intensity level $j$ (from 0 to $G-1=255$)."""

def calculate_manual_histogram(I_gray):
    # Determine the number of possible gray levels (G)
    G = 256

    # 1. Compute Histogram (H)
    # Initialize an array H of size G=256 to zero
    H = [0] * G

    # Get image dimensions (H, W)
    height, width = I_gray.shape

    # Iterate through every pixel in the grayscale image
    for y in range(height):
        for x in range(width):
            # Read the intensity value of the pixel
            intensity = I_gray[y, x]

            # Increment the corresponding bin in the histogram
            # Note: I_gray[y, x] is the index j for H[j]
            H[intensity] += 1

    # Total Pixels (N)
    # This is also the size of the image, but we calculate it from the histogram for robustness
    N = sum(H)

    print(f"Total number of pixels (N): {N}")

    return H, N

""" Manual Global Mean CalculationThe global mean intensity $\mu_T$ is needed for the between-class variance calculation. It is defined as:$$\mu_T = \frac{1}{N} \sum_{j=0}^{G-1} j \cdot H(j)$$"""

def calculate_global_mean(H, N):
    G = 256
    total_intensity_sum = 0

    # Iterate through all possible gray levels j (0 to 255)
    for j in range(G):
        # Calculate j * H(j): Intensity level multiplied by its frequency
        total_intensity_sum += j * H[j]

    # Global Mean (mu_T)
    mu_T = total_intensity_sum / N

    print(f"Global Mean Intensity (mu_T): {mu_T:.2f}")

    return mu_T

"""Combining and Preparing for Otsu Search. Now we normalize histogram $P(j)$ for the subsequent calculations of class probabilities ($\omega_k$) and class means ($\mu_k$)."""

def prepare_otsu_parameters(H, N, mu_T):
    # Calculate the Normalized Histogram P(j)
    # This is the probability distribution of pixel intensities
    P = [count / N for count in H]

    # The search function will need H, P, N, and mu_T
    # We can pack them together for the next step.
    return P, mu_T

# --- Main Execution continuation ---

# Assuming I_gray is the result from the previous Grayscale Conversion step
# Example placeholder for I_gray if running this section separately:
# I_gray = np.array([[10, 20, 30], [20, 30, 40]], dtype=np.uint8)

# Step 2.1: Calculate Histogram and N
H, N = calculate_manual_histogram(I_gray)

# Step 2.2: Calculate Global Mean
mu_T = calculate_global_mean(H, N)

# Step 2.3: Prepare Normalized Histogram
P, mu_T_ready = prepare_otsu_parameters(H, N, mu_T)

# Now P (Normalized Histogram) and mu_T_ready (Global Mean)
# are ready for the core search algorithm (Step 3).

"""Optimization Search for $t_1^*$ and $t_2^*$1. Pre-Calculation: Cumulative Sums (Optimization)To significantly speed up the nested loop calculations, we pre-calculate the cumulative probability ($\Omega$) and cumulative mean ($\Theta$). This avoids recalculating sums inside the loops.Let $G=256$.ParameterFormulaPurposeCumulative Probability $\Omega(j)$$\Omega(j) = \sum_{i=0}^{j} P(i)$Gives the probability $\omega$ for any class starting at $0$.Cumulative Mean $\Theta(j)$$\Theta(j) = \sum_{i=0}^{j} i \cdot P(i)$Used to calculate the numerator for class means."""

def pre_calculate_cumulative_sums(P):
    G = 256
    Omega = [0.0] * G  # Cumulative Probability
    Theta = [0.0] * G  # Cumulative Mean

    # Initialize the first element
    Omega[0] = P[0]
    Theta[0] = 0.0 # 0 * P[0] is 0

    for j in range(1, G):
        Omega[j] = Omega[j-1] + P[j]
        Theta[j] = Theta[j-1] + (j * P[j])

    return Omega, Theta

"""Nested Loop Search and Variance Calculation. We need two nested loops to check every possible combination where $0 \le t_1 < t_2 < 255$. Inside the loops, we calculate the class parameters and the objective function, $\sigma^2_B(t_1, t_2)$, using the pre-calculated sums"""

def find_optimal_thresholds(Omega, Theta, mu_T):
    G = 256
    sigma2_B_max = 0.0
    t1_star, t2_star = 0, 0

    # Iterate through all possible t1 values
    # t1 runs from 0 up to G-3 (253)
    for t1 in range(G - 2):

        # Calculate Class 0 parameters using cumulative sums
        omega0 = Omega[t1]

        # Avoid division by zero: if class 0 is empty, skip this t1
        if omega0 == 0:
            continue
        mu0 = Theta[t1] / omega0

        # Iterate through all possible t2 values
        # t2 runs from t1 + 1 up to G-2 (254)
        for t2 in range(t1 + 1, G - 1):

            # 1. Calculate Class 1 Parameters (t1+1 to t2)
            # Probability omega1 is the difference between cumulative probabilities
            omega1 = Omega[t2] - Omega[t1]

            # Avoid division by zero: if class 1 is empty, skip this t2
            if omega1 == 0:
                continue

            # Mean mu1 is the difference between cumulative means, divided by omega1
            mu1 = (Theta[t2] - Theta[t1]) / omega1

            # 2. Calculate Class 2 Parameters (t2+1 to G-1)
            # Since Omega[G-1] is approximately 1.0 (total probability),
            # omega2 can be found by 1 - (probability of C0 and C1)
            omega2 = 1.0 - Omega[t2]

            # Global mean is approximately Theta[G-1], so mu_T = Theta[G-1] / 1.0
            # If omega2 is 0, then the whole image is C0 and C1, this t2 is the upper bound.
            if omega2 == 0:
                 # This should rarely happen for t2 < G-1, but ensures safe code
                 continue

            # Mean mu2 calculation: Global mean sum (Theta[G-1]) minus the sums of C0 and C1
            # mu2 = (Theta[G-1] - Theta[t2]) / omega2
            # However, since mu_T is already provided, use the global mean properties
            # mu2 can be calculated as: (mu_T * 1.0 - mu0*omega0 - mu1*omega1) / omega2
            # A more direct calculation using cumulative sums is:
            mu2 = (mu_T - (mu0 * omega0) - (mu1 * omega1)) / omega2

            # 3. Calculate Between-Class Variance (The Objective Function)
            # The manual implementation MUST include the square of the difference
            sigma2_B = (omega0 * (mu0 - mu_T)**2 +
                        omega1 * (mu1 - mu_T)**2 +
                        omega2 * (mu2 - mu_T)**2)

            # 4. Update Optimal Thresholds
            if sigma2_B > sigma2_B_max:
                sigma2_B_max = sigma2_B
                t1_star = t1
                t2_star = t2

    return t1_star, t2_star, sigma2_B_max

"""Complete Implementation Structure: Now we bring all three steps together:"""

# Assuming P (Normalized Histogram) and mu_T (Global Mean) are available
# from the previous step.

# 1. Pre-calculate sums for efficiency
Omega, Theta = pre_calculate_cumulative_sums(P)

# 2. Run the main optimization search
t1_star, t2_star, sigma2_B_max = find_optimal_thresholds(Omega, Theta, mu_T)

print(f"\n--- Extended Otsu's Results ---")
print(f"Optimal Threshold t1*: {t1_star}")
print(f"Optimal Threshold t2*: {t2_star}")
print(f"Maximum Between-Class Variance: {sigma2_B_max:.4f}")

# The next and final step is image segmentation.

"""Image Segmentation: We will define three distinct output gray levels (e.g., Black, Mid-Gray, White) to represent the three segmented classes.

Python Implementation
This code assumes you have the grayscale image data (I_gray) and the optimal thresholds (t1_star, t2_star) available from the previous steps, and you are using the Pillow library (imported as Image) for the allowed image writing/displaying functions.
"""

from PIL import Image
import numpy as np
# Assuming I_gray, t1_star, t2_star are available here.
# Example placeholders (replace with actual calculated values):
# I_gray = ... (the 2D numpy array of the grayscale image)
# t1_star = 75
# t2_star = 180

def segment_and_output_image(I_gray, t1_star, t2_star):

    # Define Output Gray Levels for the Three Regions
    # These must be different values to distinguish the regions visually.
    VALUE_C0 = 0      # Black for the lowest intensity class (Background)
    VALUE_C1 = 127    # Mid-Gray for the middle class
    VALUE_C2 = 255    # White for the highest intensity class (Foreground)

    # Get image dimensions
    height, width = I_gray.shape

    # Create the output image array, I_seg
    I_seg = np.zeros((height, width), dtype=np.uint8)

    print(f"\nSegmenting image using thresholds t1={t1_star} and t2={t2_star}...")

    # Iterate through every pixel to perform segmentation
    for y in range(height):
        for x in range(width):
            intensity = I_gray[y, x]

            # Classification Logic:

            # Class C0: I <= t1*
            if intensity <= t1_star:
                I_seg[y, x] = VALUE_C0

            # Class C1: t1* < I <= t2*
            elif intensity <= t2_star:
                I_seg[y, x] = VALUE_C1

            # Class C2: I > t2*
            else:
                I_seg[y, x] = VALUE_C2

    print("Segmentation complete.")

    # Output Results (Using Allowed Library Functions)
    try:
        # Create a PIL Image object from the resulting numpy array
        segmented_image = Image.fromarray(I_seg, mode='L') # 'L' mode for 8-bit grayscale

        output_file_name = "data13_segmented_3level.bmp"
        segmented_image.save(output_file_name)

        print(f"Segmented image saved successfully as {output_file_name}.")
        # segmented_image.show() # Uncomment to display the image immediately

    except Exception as e:
        print(f"Error saving or displaying image: {e}")

    return I_seg

# Example of how to call this function after the search (Step 3) is done:
# final_segmented_image = segment_and_output_image(I_gray, t1_star, t2_star)

"""Now we go to the next two images The goal of this step is to transform the 3-channel color data into a 1-channel grayscale array, which will be the input for the Otsu algorithm.

1. Read Color Image and Initialize Data
For both basket_balls.bmp and tiger1.bmp, you must first read the file into a data structure that allows you to access the Red (R), Green (G), and Blue (B) values for every pixel.

The allowed library function handles the complexity of the .bmp file format.
"""

from PIL import Image
import numpy as np

def read_color_image(file_path):
    """Uses the allowed library function to read the image."""
    try:
        color_image = Image.open(file_path)
        # Convert the image to a NumPy array (Height x Width x 3)
        # 3 represents the R, G, B channels.
        rgb_data = np.array(color_image, dtype=np.uint8)

        height, width, _ = rgb_data.shape
        # Create a new 2D array for the grayscale output
        I_gray = np.zeros((height, width), dtype=np.uint8)

        print(f"File: {file_path} loaded. Dimensions: {width}x{height}")
        return rgb_data, I_gray, width, height

    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None, None, 0, 0

"""Manual Grayscale Conversion ImplementationThe formula you must implement is the standard luminance method used for HDTV broadcasting (often called ITU-R BT.709, though the coefficients used are closer to the older BT.601 standard):$$I = \text{round}(\mathbf{0.299}R + \mathbf{0.587}G + \mathbf{0.114}B)$$You are prohibited from using any built-in library function for this conversion; you must iterate through the pixels and calculate this manually. The large coefficient for Green ($\mathbf{0.587}$) reflects the human eye's higher sensitivity to green light"""

def manual_grayscale_conversion(rgb_data, I_gray, width, height):
    """Manually converts the RGB data to grayscale intensity I."""

    # Define the coefficients as floating-point numbers
    R_COEFF = 0.299
    G_COEFF = 0.587
    B_COEFF = 0.114

    # Iterate through every row (y) and column (x)
    for y in range(height):
        for x in range(width):

            # Manually extract the R, G, B values for the current pixel
            R = rgb_data[y, x, 0]
            G = rgb_data[y, x, 1]
            B = rgb_data[y, x, 2]

            # Apply the required linear combination formula
            I_float = (R_COEFF * R) + (G_COEFF * G) + (B_COEFF * B)

            # Round the result and cast it to an 8-bit integer (0-255)
            # This is necessary because intensity values must be integers (gray levels).
            I_gray[y, x] = np.round(I_float).astype(np.uint8)

    print("Manual grayscale conversion complete.")
    return I_gray

"""Now we execute on both images, you would call the functions sequentially"""

# --- Execution for basket_balls.bmp ---
file1 = "basket_balls.bmp"
rgb_data1, I_gray1, w1, h1 = read_color_image(file1)
if rgb_data1 is not None:
    I_gray1 = manual_grayscale_conversion(rgb_data1, I_gray1, w1, h1)
    # I_gray1 is now ready for Step B (Histogram Calculation)

# --- Execution for tiger1.bmp ---
file2 = "tiger1.bmp"
rgb_data2, I_gray2, w2, h2 = read_color_image(file2)
if rgb_data2 is not None:
    I_gray2 = manual_grayscale_conversion(rgb_data2, I_gray2, w2, h2)
    # I_gray2 is now ready for Step B (Histogram Calculation)

"""Histogram and Global Mean CalculationManually compute the 256-level histogram $H(j)$ from the grayscale image.Manually calculate the total number of pixels $N$ and the Global Mean $\mu_T$.Calculate the Normalized Histogram (Probability Distribution) $P(j) = H(j)/N$.

This process uses the 2D grayscale array ($I_{gray}$) generated in Step A. We'll outline the function and then show how to execute it for both basket_balls.bmp and tiger1.bmp.1. Manual Histogram CalculationThe histogram $H(j)$ is an array of size 256 where each index $j$ stores the count of pixels with intensity $j$.2. Manual Global Mean CalculationThe Global Mean ($\mu_T$) is the average intensity of the entire image. We calculate it using the histogram:$$\mu_T = \frac{1}{N} \sum_{j=0}^{G-1} j \cdot H(j)$$3. Normalized Histogram (Probability Distribution)The Normalized Histogram $P(j)$ is the probability of a pixel having intensity $j$, which is used directly in the Otsu objective function:$$P(j) = H(j)/N$$
"""

import numpy as np

def calculate_image_statistics(I_gray):
    """
    Manually calculates the histogram, total pixels, and global mean.

    Args:
        I_gray (np.array): The 2D grayscale image array (0-255).

    Returns:
        tuple: (P, mu_T) - Normalized Histogram and Global Mean.
    """
    G = 256 # Number of gray levels

    # 1. Manually Compute Histogram (H) and Total Pixels (N)
    H = np.zeros(G, dtype=np.int32)
    height, width = I_gray.shape

    # Iterate through every pixel
    for y in range(height):
        for x in range(width):
            intensity = I_gray[y, x]
            H[intensity] += 1

    # Total Pixels (N)
    N = height * width
    # Note: Using height * width is equivalent to sum(H) and avoids an extra loop/call.

    # 2. Manually Calculate Global Mean (mu_T)
    total_intensity_sum = 0

    # Iterate through all possible gray levels j (0 to 255)
    for j in range(G):
        # Calculate j * H(j): Intensity level multiplied by its frequency
        total_intensity_sum += j * H[j]

    mu_T = total_intensity_sum / N

    # 3. Calculate Normalized Histogram (P)
    P = H / N

    print(f"  Total Pixels (N): {N}")
    print(f"  Global Mean (mu_T): {mu_T:.4f}")

    return P, mu_T

# --- Execution for basket_balls.bmp ---
print("--- Statistics for basket_balls.bmp ---")
# P1 is the Normalized Histogram, mu_T1 is the Global Mean
P1, mu_T1 = calculate_image_statistics(I_gray1)

# --- Execution for tiger1.bmp ---
print("\n--- Statistics for tiger1.bmp ---")
P2, mu_T2 = calculate_image_statistics(I_gray2)
# P2 is the Normalized Histogram, mu_T2 is the Global Mean

"""Multi-Level Otsu Optimization SearchThis step uses the Normalized Histogram ($P$) and the Global Mean ($\mu_T$) calculated in the last step. Pre-Calculation: Cumulative Sums (Optimization)Calculating the class probabilities ($\omega_k$) and the numerators for class means ($\mu_k \cdot \omega_k$) repeatedly inside the nested loops is computationally expensive. We avoid this by pre-calculating the Cumulative Probability ($\Omega$) and Cumulative Mean ($\Theta$).Let $G=256$.ParameterFormulaCumulative Probability $\Omega(j)$$\Omega(j) = \sum_{i=0}^{j} P(i)$Cumulative Mean $\Theta(j)$$\Theta(j) = \sum_{i=0}^{j} i \cdot P(i)$"""

import numpy as np

def pre_calculate_cumulative_sums(P):
    """Calculates Omega and Theta arrays for efficient searching."""
    G = 256
    Omega = np.zeros(G, dtype=np.float64)  # Cumulative Probability
    Theta = np.zeros(G, dtype=np.float64)  # Cumulative Mean Sum (j * P(j))

    # Pre-calculate sums for all indices
    for j in range(G):
        Omega[j] = Omega[j-1] + P[j] if j > 0 else P[j]
        Theta[j] = Theta[j-1] + (j * P[j]) if j > 0 else 0.0

    return Omega, Theta

"""Nested Loop Search and Variance MaximizationThe goal is to find $(t_1^*, t_2^*)$ that maximizes the Between-Class Variance:$$\sigma^2_B(t_1, t_2) = \omega_0(\mu_0 - \mu_T)^2 + \omega_1(\mu_1 - \mu_T)^2 + \omega_2(\mu_2 - \mu_T)^2$$"""

def find_optimal_thresholds(Omega, Theta, mu_T):
    """
    Finds the optimal thresholds t1 and t2 by maximizing the
    between-class variance (sigma2_B).
    """
    G = 256
    sigma2_B_max = 0.0
    t1_star, t2_star = 0, 0

    # Outer Loop: Iterate through t1 (0 to G-3)
    for t1 in range(G - 2):

        # --- Class 0 (0 to t1) ---
        omega0 = Omega[t1]

        # Skip if C0 is empty to avoid division by zero
        if omega0 == 0.0:
            continue
        mu0 = Theta[t1] / omega0

        # Inner Loop: Iterate through t2 (t1 + 1 to G-2)
        for t2 in range(t1 + 1, G - 1):

            # --- Class 1 (t1 + 1 to t2) ---
            omega1 = Omega[t2] - Omega[t1]

            # Skip if C1 is empty
            if omega1 == 0.0:
                continue
            mu1 = (Theta[t2] - Theta[t1]) / omega1

            # --- Class 2 (t2 + 1 to G-1) ---
            # Total probability is 1.0
            omega2 = 1.0 - Omega[t2]

            # Skip if C2 is empty
            if omega2 == 0.0:
                 continue

            # Mean mu2 calculation using the property that the total mean is weighted by class means:
            # mu_T = omega0*mu0 + omega1*mu1 + omega2*mu2
            # mu2 = (mu_T - (omega0*mu0 + omega1*mu1)) / omega2

            # Since mu0 and mu1 are calculated based on Theta and Omega, the calculation is robust:
            mu2 = (Theta[G - 1] - Theta[t2]) / omega2 # Theta[G-1] is the total intensity sum

            # --- Calculate Between-Class Variance ---
            # **This is the core objective function to maximize**
            sigma2_B = (omega0 * (mu0 - mu_T)**2 +
                        omega1 * (mu1 - mu_T)**2 +
                        omega2 * (mu2 - mu_T)**2)

            # --- Update Optimal Thresholds ---
            if sigma2_B > sigma2_B_max:
                sigma2_B_max = sigma2_B
                t1_star = t1
                t2_star = t2

    return t1_star, t2_star, sigma2_B_max

"""Assuming you have $P1, \mu_{T1}$ (for basket_balls.bmp) and $P2, \mu_{T2}$ (for tiger1.bmp) from previous step, the execution is as follows"""

# --- Execution for basket_balls.bmp ---
Omega1, Theta1 = pre_calculate_cumulative_sums(P1)
t1_star1, t2_star1, max_sigma1 = find_optimal_thresholds(Omega1, Theta1, mu_T1)

print("\n--- Results for basket_balls.bmp ---")
print(f"Optimal Threshold t1*: {t1_star1}")
print(f"Optimal Threshold t2*: {t2_star1}")
print(f"Max Between-Class Variance: {max_sigma1:.4f}")

# --- Execution for tiger1.bmp ---
Omega2, Theta2 = pre_calculate_cumulative_sums(P2)
t1_star2, t2_star2, max_sigma2 = find_optimal_thresholds(Omega2, Theta2, mu_T2)

print("\n--- Results for tiger1.bmp ---")
print(f"Optimal Threshold t1*: {t1_star2}")
print(f"Optimal Threshold t2*: {t2_star2}")
print(f"Max Between-Class Variance: {max_sigma2:.4f}")

"""Classification and Image CreationFor each pixel with intensity $I$, the classification logic is:Class $C_0$ (Background): If $I \le t_1^*$, assign a low value (e.g., 0).Class $C_1$ (Middle Region): If $t_1^* < I \le t_2^*$, assign a medium value (e.g., 127).Class $C_2$ (Foreground): If $I > t_2^*$, assign a high value (e.g., 255)."""

from PIL import Image
import numpy as np

def segment_and_output_image(I_gray, t1_star, t2_star, input_file_name):
    """
    Applies the optimal thresholds to segment the image and saves the result.

    Args:
        I_gray (np.array): The 2D grayscale image array.
        t1_star (int): The lower optimal threshold.
        t2_star (int): The upper optimal threshold.
        input_file_name (str): The name of the original file for output naming.
    """

    # Define distinct output gray levels for visualization
    VALUE_C0 = 0      # Black
    VALUE_C1 = 127    # Mid-Gray
    VALUE_C2 = 255    # White

    height, width = I_gray.shape
    I_seg = np.zeros((height, width), dtype=np.uint8)

    # Manual Segmentation Loop
    for y in range(height):
        for x in range(width):
            intensity = I_gray[y, x]

            if intensity <= t1_star:
                I_seg[y, x] = VALUE_C0
            elif intensity <= t2_star:
                I_seg[y, x] = VALUE_C1
            else: # intensity > t2_star
                I_seg[y, x] = VALUE_C2

    # Output Threshold Values (Required Text Output)
    print(f"\n--- Segmentation Results for {input_file_name} ---")
    print(f"Optimal Threshold t1*: {t1_star}")
    print(f"Optimal Threshold t2*: {t2_star}")

    # Output Segmented Image (Required Image Output)
    try:
        # Construct output file name
        base_name = input_file_name.split('.')[0]
        output_file_name = f"{base_name}_segmented_3level.bmp"

        # Create a PIL Image object from the resulting numpy array
        segmented_image = Image.fromarray(I_seg, mode='L')
        segmented_image.save(output_file_name) # Save the image using allowed function

        print(f"Segmented image saved as: {output_file_name}")

    except Exception as e:
        print(f"Error saving image: {e}")

    return I_seg

"""Assuming the following variables were derived from Steps A, B, and C:

I_gray1, t1_star1, t2_star1 for basket_balls.bmp

I_gray2, t1_star2, t2_star2 for tiger1.bmp
"""

# --- Execution for basket_balls.bmp ---
# (Assume I_gray1, t1_star1, t2_star1 are available)
final_seg_1 = segment_and_output_image(I_gray1, t1_star1, t2_star1, "basket_balls.bmp")

# --- Execution for tiger1.bmp ---
# (Assume I_gray2, t1_star2, t2_star2 are available)
final_seg_2 = segment_and_output_image(I_gray2, t1_star2, t2_star2, "tiger1.bmp")

"""## Project Report: Multi-Level Otsu Thresholding

This report outlines the steps taken to implement a multi-level Otsu thresholding algorithm for image segmentation, as demonstrated in the accompanying notebook. The project involves reading color images, converting them to grayscale, calculating image statistics (histogram and mean), finding optimal thresholds using Otsu's method, and finally segmenting the images based on the determined thresholds.

### Step 1: Grayscale Conversion

The initial step for each input color image (`data13.bmp`, `basket_balls.bmp`, and `tiger1.bmp`) is to convert it into a single-channel grayscale image. This is achieved by reading the color image using the Pillow library and then manually applying a weighted sum to the R, G, and B components of each pixel based on the formula:

$$I = \text{round}(0.299R + 0.587G + 0.114B)$$

This manual conversion ensures adherence to the project constraints of avoiding built-in library functions for core image processing steps. The resulting grayscale image is stored as a 2D NumPy array.

### Step 2: Histogram and Global Mean Calculation

Once the grayscale image is obtained, the next step is to calculate its statistical properties: the histogram and the global mean.

*   **Histogram ($H(j)$):** A 256-level histogram is manually computed by iterating through each pixel of the grayscale image and counting the occurrences of each intensity level (0-255).
*   **Total Pixels ($N$):** The total number of pixels in the image is calculated.
*   **Global Mean ($\mu_T$):** The average intensity of the entire image is calculated using the formula:
    $$\mu_T = \frac{1}{N} \sum_{j=0}^{G-1} j \cdot H(j)$$
*   **Normalized Histogram ($P(j)$):** The histogram is normalized to create a probability distribution of pixel intensities:
    $$P(j) = H(j)/N$$

These statistics are crucial inputs for the Otsu thresholding algorithm.

### Step 3: Multi-Level Otsu Optimization Search

This is the core of the multi-level thresholding process. The goal is to find two optimal thresholds ($t_1^*$ and $t_2^*$) that maximize the between-class variance ($\sigma^2_B$) for three classes (background, middle region, and foreground).

To optimize the search, cumulative sums of the normalized histogram are pre-calculated:

*   **Cumulative Probability ($\Omega(j)$):** $\Omega(j) = \sum_{i=0}^{j} P(i)$
*   **Cumulative Mean ($\Theta(j)$):** $\Theta(j) = \sum_{i=0}^{j} i \cdot P(i)$

A nested loop iterates through all possible combinations of $t_1$ and $t_2$ where $0 \le t_1 < t_2 < 255$. For each combination, the class probabilities ($\omega_k$) and class means ($\mu_k$) for the three classes ($k=0, 1, 2$) are calculated efficiently using the pre-calculated cumulative sums. The between-class variance is then calculated using the formula:

$$\sigma^2_B(t_1, t_2) = \omega_0(\mu_0 - \mu_T)^2 + \omega_1(\mu_1 - \mu_T)^2 + \omega_2(\mu_2 - \mu_T)^2$$

The thresholds $(t_1, t_2)$ that yield the maximum $\sigma^2_B$ are selected as the optimal thresholds ($t_1^*$ and $t_2^*$).

### Step 4: Image Segmentation

The final step is to segment the grayscale image using the optimal thresholds $t_1^*$ and $t_2^*$. Each pixel in the grayscale image is classified into one of three classes based on its intensity:

*   **Class $C_0$ (Background):** If $I \le t_1^*$, the pixel is assigned a low gray level value (e.g., 0).
*   **Class $C_1$ (Middle Region):** If $t_1^* < I \le t_2^*$, the pixel is assigned a medium gray level value (e.g., 127).
*   **Class $C_2$ (Foreground):** If $I > t_2^*$, the pixel is assigned a high gray level value (e.g., 255).

The segmented image is then created as a new 2D NumPy array with these assigned gray levels. Finally, the segmented image is saved as a `.bmp` file using the allowed Pillow library function. The optimal threshold values are also printed as part of the output.

This process was applied to `data13.bmp`, `basket_balls.bmp`, and `tiger1.bmp` to produce their respective 3-level segmented images.
"""